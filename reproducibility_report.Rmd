---
title: "COD Reproducibility Report"
output:
  html_document:
    toc: true
    toc_float: true
---

#### Article ID: DvcDF
#### Pilot: Sara Altman
#### Co-pilot: Tom Hardwicke  
#### Start date: [Insert start date - use US format]
#### End date: [Insert end date - use US format]   

-------

#### Methods summary: 
The experimenters tested sixty-two participants. Half were monolingual and half were bilingual. The experimenters gave the participants working memory and non-verbal reasoning tasks to ensure that the bilingual and monolingual groups were similar in terms of cognitive functioning. Working memory was assessed using the Wechsler Adult Intelligence Scale IV. Non-verbal reasoning was assessed using the Raven's Advanced Progressive Matrices. The experimenter's also checked the English language proficiency of the bilinguals. 

To measure metacognitive performance, the experimenters administered a dot discrimination task. In the dot discrimination task, participants were presented with two white circles on a black background. The participants were asked to choose which circle contained the most dots within it's boundary. The differences in dot numbers were modified with a staircase procedure so that accuracy was normalised at 71%. Participants completed 8 blocks of the dot discrimination task, each with 25 trials. 

------

#### Target outcomes:

The experimenters conducted a t-test to compare the bilinguals' and monolinguals' choice response time in the dot discrimination task. 

> We compared the bilinguals’ and monolinguals’ performance with regard to their first order accuracy (measured by percentage of correct responses), the difficulty of the trials (measured by dot difference) and response time of the choice and the confidence judgment (both measured in seconds). The results of all these anal- yses are summarised in Table 3.
The monolingual group had a mean accuracy of 70.98%, with a standard deviation of 1.06%, whilst the bilingual group had mean accuracy of 70.79% with a standard deviation of 1.23%. This indi- cates that the staircase procedure successfully standardised accu- racy across participants. There were no significant group differences with regard to trial difficulty, with a mean dot differ- ence of 4.64 for the monolinguals and 4.34 for the bilinguals. Addi- tionally, with regards to response time for the confidence judgments there was no difference between the groups: the mono-lingual group took, on average, 1179 ms to respond compared to 1112 ms for the bilinguals.
However, the groups did differ with regards to choice response time; an independent samples t-test showed that bilinguals (M = 2679 ms, SD = 923 ms) were significantly faster than mono- linguals (M = 3360 ms, SD = 1475 ms, t(50.38) =  2.18, p = .03, d = 0.55). A random slopes multilevel model (MLM) revealed that this relationship was significantly mediated by block (see Fig. 3; for more detailed information about the MLM fitting see Appendix A). Monolinguals were set to be the reference category for this analysis and all subsequent MLMs. The model tells us that the main-effect of group became statistically non-significant when the block-group interaction was accounted for (b = 283.11, t (64.03) = 0.71, p = 0.48). The main effect of block was also non- significant (b = 19.23, t(64.03) = 0.61, p = 0.54), meaning that the response speed of the monolinguals did not change significantly over time, when individual variation in intercepts and slopes were accounted for. The bilingual group ⁄ block interaction was signifi- cant (b =  88, t(64.03) =  2.01, p = .05), meaning that bilinguals, as a group, became faster as the task progressed.
Two participants in the monolingual group displayed outlying values for one variable (difficulty and response time, respectively). In order to ensure that these outliers did not unduly influence the group-wise comparisons they were both capped at 3 standard deviations above the group mean. Capping these values did not change the results for difficulty (t(59.78) = 1.29, p = .20, d = 0.33) or for response time (t(55.17) = 2.24, p = .03, d = 0.57).

------

[The chunk below sets up some formatting options for the R Markdown document]

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Step 1: Load packages

[Some useful packages are being loaded below. You can add any additional ones you might need too.]

```{r}
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(CODreports) # custom report functions
library(readr)
library(lsr)
library(lme4)
library(stringr)

data_file <- "~/GitHub/skaltman/set_DvcDF/data/data.xlsx"
rename_all <- function(df, fun){ 
  setNames(df, fun(names(df))) 
  }
```

## Step 2: Load data

```{r}
column_names <- c("id", 
                  "group", 
                  "first_accuracy", 
                  "first_rt",
                  "first_dot_diff",
                  "second_confidence",
                  "second_mratio",
                  "mratio_1",
                  "mratio_2",
                  "rt_1",
                  "rt_2",
                  "rt_3",
                  "rt_4",
                  "rt_5",
                  "rt_6",
                  "rt_7",
                  "rt_8")


#I recalculated the average reaction times because the ones given were rounded                                                        
data <- read_excel(data_file, sheet = 2, skip = 2, col_names = column_names) %>% 
  mutate(first_rt = (rt_1 + rt_2 + rt_3 + rt_4 + rt_5 + rt_6 + rt_7 + rt_8)/8) 

demographics <- 
  read_excel(data_file, sheet = 1) %>% 
  rename_all(tolower) %>% 
  rename(id = `participant id`) %>% 
  filter(!is.na(id))
```


## Step 3: Tidy data

```{r}
data_tidy <-
  data %>% 
  group_by(id) %>% 
  gather(key = "measure", value = "value", first_accuracy:rt_8)
```

## Step 4: Run analysis

### Pre-processing

> Two participants in the monolingual group displayed outlying values for one variable (difficulty and response time, respectively). In order to ensure that these outliers did not unduly influence the group-wise comparisons they were both capped at 3 standard deviations above the group mean. Capping these values did not change the results for difficulty (t(59.78) = 1.29, p = .20, d = 0.33) or for response time (t(55.17) = 2.24, p = .03, d = 0.57).

The following code chunk confirms that there are two participants in the monolingual group with outlying values for one variable (difficulty and response time).

```{r}
mean_diff = mean(data$first_dot_diff, na.rm = TRUE)
sd_diff = sd(data$first_dot_diff, na.rm = TRUE)
mean_rt = mean(data$first_rt, na.rm = TRUE)
sd_rt = sd(data$first_rt, na.rm = TRUE)

data_tidy %>% 
  spread(key = measure, value = value) %>% 
  filter(first_dot_diff > mean_diff + 3*sd_diff | first_rt > mean_rt + 3*sd_rt)
```

This code chunk caps the values as specified in the original paper and performs the t-test:

```{r}
data_tidy_capped <-
  data_tidy %>% 
  spread(key = measure, value = value) %>% 
  mutate(first_dot_diff = ifelse(first_dot_diff > mean_diff + 3*sd_diff, 
                                 mean_diff + 3*sd_diff, 
                                 first_dot_diff),
         first_rt = ifelse(first_rt > mean_rt + 3*sd_rt, 
                                 mean_rt + 3*sd_rt, 
                                 first_rt))

monolingual_capped <- 
  data_tidy_capped %>% 
  filter(group == "Monolingual")

bilingual_capped <- 
  data_tidy_capped %>% 
  filter(group == "Bilingual")

t_test_rt_capped <- t.test(x = monolingual_capped$first_rt, 
                           y = bilingual_capped$first_rt)
d_rt_capped <- cohensD(x = monolingual_capped$first_rt, 
                       y = bilingual_capped$first_rt)
t_test_diff_capped <- t.test(x = monolingual_capped$first_dot_diff, 
                             y = bilingual_capped$first_dot_diff)
d_diff_capped <- cohensD(x = monolingual_capped$first_dot_diff, 
                         y = bilingual_capped$first_dot_diff)

t_tests_capped <-
  tibble(
    measure = c("Response time", "Difficulty"),
    t = c(abs(t_test_rt_capped$statistic), abs(t_test_diff_capped$statistic)),
    df = c(t_test_rt_capped$parameter, t_test_diff_capped$parameter),
    p = c(t_test_rt_capped$p.value, t_test_diff_capped$p.value),
    d = c(d_rt_capped, d_diff_capped)
  )

kable(t_tests_capped, digits = 2)
```

The t-value for difficulty is slightly off. As are the degrees of freedom. The Cohen's d values are the same as originally reported, as are the p-values. 

### Descriptive statistics

The original authors reported the mean and standard deviations of the accuracy measure for both groups:

> The monolingual group had a mean accuracy of 70.98%, with a standard deviation of 1.06%, whilst the bilingual group had mean accuracy of 70.79% with a standard deviation of 1.23%.

The following code chunk checks these calculations:

```{r}
accuracy_tibble <-
  data_tidy %>% 
  filter(measure == "first_accuracy") %>% 
  group_by(group) %>% 
  summarise(mean_accuracy = mean(value*100, na.rm = TRUE),
            sd_accuracy = sd(value*100, na.rm = TRUE)) %>% 
  arrange(desc(group))

knitr::kable(accuracy_tibble, digits = 3)
```

The means and standard deviations are slightly off.

The original authors also calculated the mean dot differences for each group:

> There were no significant group differences with regard to trial difficulty, with a mean dot differ- ence of 4.64 for the monolinguals and 4.34 for the bilinguals. 

The following code chunk calculates these means:

```{r}
dot_diff_tibble <-
  data_tidy %>% 
  filter(measure == "first_dot_diff") %>% 
  group_by(group) %>% 
  summarise(mean_dot_diff = mean(value, na.rm = TRUE),
            sd_dot_diff = sd(value, na.rm = TRUE)) %>% 
  arrange(desc(group))

knitr::kable(dot_diff_tibble %>% select(1:2), digits = 2)
```

The values reported in the above quote are different from the values reported in Table 3 of the original paper (recreated below). In Table 3, the reported mean for the monolinguals is 4.33 and the reported mean for the bilinguals is 4.64. The mean for the bilinguals that I calculated matches the mean given in Table 3. The mean for the monolinguals that I calculated is .02 below the mean given in Table 3. 

> Addi- tionally, with regards to response time for the confidence judgments there was no difference between the groups: the mono-lingual group took, on average, 1179 ms to respond compared to 1112 ms for the bilinguals.

```{r}
confidence_tibble <-
  data_tidy %>% 
  filter(measure == "second_confidence") %>% 
  group_by(group) %>% 
  summarise(mean_confidence_rt = mean(value * 1000, na.rm = TRUE),
            sd_confidence_rt = sd(value * 1000, na.rm = TRUE)) %>% 
  arrange(desc(group))

knitr::kable(confidence_tibble %>% select(1:2), digits = 0)
```

The monolingual mean matches the reported value. The bilingual mean is off by 1 ms. 

The authors then calculate the differences in choice response time between groups:

> However, the groups did differ with regards to choice response time; an independent samples t-test showed that bilinguals (M = 2679 ms, SD = 923 ms) were significantly faster than mono- linguals (M = 3360 ms, SD = 1475 ms, t(50.38) =  2.18, p = .03, d = 0.55).

The following code chunk computes the mean and standard deviations for each group:

```{r}
rt_tibble <- 
  data_tidy %>% 
  filter(measure == "first_rt") %>% 
  group_by(group) %>% 
  summarise(mean_choice_rt = mean(value*1000, na.rm = TRUE),
            sd_choice_rt = sd(value*1000, na.rm = TRUE)) %>% 
  arrange(desc(group))

knitr::kable(rt_tibble, digits = 0)
```

The calculated standard deviations match the standard deviations reported in the original paper. The calculated bilingual mean matches the standard deviations reported in the original paper. However, the calculated monolingual means differs from the mean given in the original paper by 1 ms. 

This code conducts a t-test for the difference in response times between the two groups:
```{r}
monolingual_rt <- data_tidy %>% filter(group == "Monolingual", measure == "first_rt") %>% .$value
bilingual_rt <- data_tidy %>% filter(group == "Bilingual", measure == "first_rt") %>% .$value

t_test_rt <- t.test(x = monolingual_rt, y = bilingual_rt)
cohens_d_rt <- cohensD(x = monolingual_rt, y = bilingual_rt)

tibble_rt <-
  tibble(measure = "Response times",
         t = t_test$statistic, 
         df = t_test$parameter,
         p = t_test$p.value, 
         d = cohens_d)

kable(tibble_rt, digits = 2)
```

The calculated values all match the reported values, except for the degrees of freedom, which is off by .01. 

### Inferential statistics

The original authors conducted a linear mixed-effects model with choice response time as the response, described in the following text:

> A random slopes multilevel model (MLM) revealed that this relationship was significantly mediated by block (see Fig. 3; for more detailed information about the MLM fitting see Appendix A). Monolinguals were set to be the reference category for this analysis and all subsequent MLMs. The model tells us that the main-effect of group became statistically non-significant when the block-group interaction was accounted for (b = 283.11, t (64.03) = 0.71, p = 0.48). The main effect of block was also non- significant (b = 19.23, t(64.03) = 0.61, p = 0.54), meaning that the response speed of the monolinguals did not change significantly over time, when individual variation in intercepts and slopes were accounted for. The bilingual group ⁄ block interaction was signifi- cant (b =  88, t(64.03) =  2.01, p = .05), meaning that bilinguals, as a group, became faster as the task progressed.

More details about the model were provided in Appendix A:

> The multilevel regression analyses reported in this paper were conducted using the lme4 package in R (Bates, Maechler, & Bolker, 2011) Degrees of freedom and p-values were obtained using the Kenward-Roger approximation, as implemented in the pbkertest package (Halekoh & Hojsgaard, 2011)...Table A1 lists the various models we attempted to fit, Fig. A1 shows the BIC scores for all the response time models. Table A2 show the full model specification for model 3, which is the best-fitting model, and the model that is reported in the main text of the paper.

![](http://web.stanford.edu/~skaltman/table_mixedeffects.png)

The following code chunk performs this mixed-effects model:

```{r}
data_tidy2 <-
  data_tidy %>% 
  spread(key = measure, value = value) %>% 
  gather(starts_with("rt"), key = "block", value = "rt") %>% 
  mutate(block = str_replace(block, "rt_", ""),
         rt = 1000*rt) %>% 
  left_join(demographics, by = c("id", "group"))

data_tidy2$first_rt

fit <- lmer(rt ~  (1|id) + group + block + block*group + (0 + group|block) + 
              (0 + block*group|block), data = data_tidy2)
fit
```

![](http://web.stanford.edu/~skaltman/fig3.png)

The following chunk recreates the above plot:

```{r}
data_tidy2 %>% 
  mutate(group = factor(group, levels = c("Monolingual", 
                                       "Bilingual")),
         block = as.integer(block)) %>% 
  group_by(group, block) %>% 
  summarise(avg_rt = 1000*mean(rt, na.rm = TRUE),
            se     = 1000*(sd(rt) / sqrt(n())),
            y_min = avg_rt - ((1.96 * se)/2), 
            y_max = avg_rt + ((1.96 * se)/2)) %>% 
  ggplot(aes(block, avg_rt, color = group)) +
  geom_point() +
  geom_line(show.legend = FALSE) +
  geom_linerange(aes(ymin = y_min, ymax = y_max), show.legend = FALSE) +
  coord_cartesian(ylim = c(2200, 4000)) +
  scale_x_continuous(breaks = seq(1, 8)) + 
  scale_y_continuous(breaks = seq(2200, 4000, 200)) +
  labs(x = "Block",
       y = "Response Time (ms)") +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.background = element_blank(),
        axis.line.x = element_line(),
        axis.ticks = element_blank()) 
```

![](http://web.stanford.edu/~skaltman/table3.png)

The following code chunk recreates the above table:

```{r}
all_measures <-
  accuracy_tibble %>% 
  left_join(dot_diff_tibble, by = "group") %>% 
  left_join(confidence_tibble, by = "group") %>% 
  left_join(rt_tibble, by = "group")

monolingual <- 
  all_measures %>% 
  filter(group == "Monolingual")

bilingual <-
  all_measures %>% 
  filter(group == "Bilingual")

t_test_accuracy = t.test(x = data_tidy %>% 
                             filter(group == "Monolingual", measure == "first_accuracy") %>% 
                             .$value,
                         y = data_tidy %>% 
                             filter(group == "Bilingual", measure == "first_accuracy") %>% 
                             .$value)

t_test_difficulty = t.test(x = data_tidy %>% 
                             filter(group == "Monolingual", measure == "first_dot_diff") %>% 
                             .$value,
                         y = data_tidy %>% 
                             filter(group == "Bilingual", measure == "first_dot_diff") %>% 
                             .$value)

t_test_confidence = t.test(x = data_tidy %>% 
                             filter(group == "Monolingual", measure == "second_confidence") %>% 
                             .$value,
                         y = data_tidy %>% 
                             filter(group == "Bilingual", measure == "second_confidence") %>% 
                             .$value)

cohens_d_accuracy = cohensD(x = data_tidy %>% 
                             filter(group == "Monolingual", measure == "first_accuracy") %>% 
                             .$value,
                         y = data_tidy %>% 
                             filter(group == "Bilingual", measure == "first_accuracy") %>% 
                             .$value)

cohens_d_difficulty = cohensD(x = data_tidy %>% 
                             filter(group == "Monolingual", measure == "first_dot_diff") %>% 
                             .$value,
                         y = data_tidy %>% 
                             filter(group == "Bilingual", measure == "first_dot_diff") %>% 
                             .$value)

cohens_d_confidence = cohensD(x = data_tidy %>% 
                             filter(group == "Monolingual", measure == "second_confidence") %>% 
                             .$value,
                         y = data_tidy %>% 
                             filter(group == "Bilingual", measure == "second_confidence") %>% 
                             .$value)

summary_tibble <-
  tibble(measure = c("Accuracy (% correct)", "Difficulty", 
                   "Response time confidence (ms)", "Response time choice (ms)"),
         `Monolinguals Mean` = c(monolingual$mean_accuracy,
                                  monolingual$mean_dot_diff,
                                  monolingual$mean_confidence_rt,
                                  monolingual$mean_choice_rt),
         `Monolinguals SD` = c(monolingual$sd_accuracy,
                                 monolingual$sd_dot_diff,
                                 monolingual$sd_confidence_rt,
                                 monolingual$sd_choice_rt),
         `Bilinguals Mean` = c(bilingual$mean_accuracy,
                                 bilingual$mean_dot_diff,
                                 bilingual$mean_confidence_rt,
                                 bilingual$mean_choice_rt),
          `Bilinguals SD` = c(bilingual$sd_accuracy,
                                bilingual$sd_dot_diff,
                                bilingual$sd_confidence_rt,
                                bilingual$sd_choice_rt),
         `t-statistic` = c(t_test_accuracy$statistic, t_test_difficulty$statistic, 
                           t_test_confidence$statistic, t_test_rt$statistic),
         df = c(t_test_accuracy$parameter, t_test_difficulty$parameter, 
                t_test_confidence$parameter, t_test_rt$parameter),
         `p-value` = c(t_test_accuracy$p.value, t_test_difficulty$p.value, 
                t_test_confidence$p.value, t_test_rt$p.value),
         `Cohen's d` = c(cohens_d_accuracy, cohens_d_difficulty, 
                         cohens_d_confidence, cohens_d_rt))

kable(summary_tibble, digit = 2)
```

## Step 5: Conclusion

```{r}
```

[Please also include a brief text summary describing your findings. If this reproducibility check was a failure, you should note any suggestions as to what you think the likely cause(s) might be.]

[This function will output information about the package versions used in this report:]

```{r session_info, include=TRUE, echo=TRUE, results='markup'}
devtools::session_info()
```
